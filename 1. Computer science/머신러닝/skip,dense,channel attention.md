---
tags:
  - ComputerScience
  - 머신러닝
---
# skip, dense을 적절하게 섞어서 최고의 머신러닝 모델을 만들어야해

#### what gpt said

머신러닝 모델을 만드는 데 있어 "skip"과 "dense"을 조합하는 것은 흥미로운 접근 방식이에요. 
Skip connections은 신경망의 깊이를 극복하고 그래디언트 소실 문제를 줄이는 데 도움을 줄 수 있어요
한편으로는 dense layers는복잡한 패턴을 학습하는 데 유용하며 모델의 복잡성을 높일 수 있어요
예를 들어, ResNet 같은 구조에서 skip connections을 사용하여 깊은 네트워크를 구축하고 dense layers를 추가하여 각 레이어의 표현력을 높일 수 있어요.

## Skip Connection

- 기존의 네트워크 아키텍처에서는 입력이 첫 번째 레이어를 거쳐 여러 레이어를 통과한 후 출력 레이어에서 결과를 생성합니다. 하지만 <mark style="background: #FF5582A6;">이 과정에서 심층 네트워크에서 그래디언트가 소실되거나 폭발하는 문제</mark>가 발생할 수 있습니다. 이를 해결하기 위해 스킵 연결은 몇 개의 레이어를 건너뛰어 이전 레이어의 출력을 현재 레이어의 출력에 직접 추가함으로써 정보가 직접적으로 흐를 수 있도록 돕습니다.
- 더 깊은 네트워크를 효과적으로 학습할 수 있게 합니다.


## Dense Connection

- Dense connection의 장점은 모든 레이어 간 정보 전달이 직접적으로 이루어진다는 것입니다. 이는 각 레이어가 이전 레이어의 모든 출력을 입력으로 받기 때문에, 다양한 특징을 고려하고 결합할 수 있어서 네트워크의 표현력을 향상시킬 수 있습니다.

- 또한, Dense connection은 그레디언트의 소실 문제를 완화하는 효과가 있습니다. 이는 뒤로 갈수록 그레디언트가 소실되는 것을 방지하고 정보의 흐름을 유지하는 데 도움이 됩니다. 이러한 특징으로 인해 DenseNet과 같은 네트워크 구조는 깊은 신경망에서도 효율적으로 학습하고 성능을 향상시킬 수 있는 장점을 가지고 있습니다.